# ==========================================
# æ¯•è®¾åç«¯ï¼šSOTA Fusion é€‚é…ç‰ˆ (EfficientNet-V2-L)
# å¯¹åº”è®­ç»ƒä»£ç ç‰ˆæœ¬ï¼šSOTA Fusion - ç¨³å®šæé€Ÿç‰ˆ
# ==========================================

import os
import io
import sys
import traceback

# å°è¯•å¯¼å…¥ä¾èµ–
try:
    import torch
    import torch.nn as nn
    from torchvision import transforms, models
    from PIL import Image
    from flask import Flask, request, jsonify
    from flask_cors import CORS
except ImportError as e:
    print(f"âŒ ä¾èµ–ç¼ºå¤±: {e}")
    sys.exit(1)

app = Flask(__name__)
CORS(app)
app.config['MAX_CONTENT_LENGTH'] = 32 * 1024 * 1024 

# ==========================================
# æ ¸å¿ƒé…ç½®
# ==========================================
# è¯·ç¡®ä¿æœåŠ¡å™¨ä¸Šçš„æ–‡ä»¶åä¸æ­¤ä¸€è‡´ï¼Œæˆ–è€…ä¿®æ”¹è¿™é‡Œ
MODEL_PATH = 'hd_effnetv2_l_best.pth' 
DEVICE = torch.device('cpu')

# å…¨å±€å˜é‡
model = None
model_name = "Unknown"

def try_load_sota_model(state_dict):
    """
    å°è¯•æ„å»º SOTA è®­ç»ƒä»£ç å®šä¹‰çš„å¤æ‚æ¨¡å‹æ¶æ„
    æ¶æ„ç‰¹å¾: EfficientNet-V2-L + 1024å±‚ + SiLU + Dropout
    """
    print("ğŸ”„ å°è¯•åŠ è½½æ¶æ„: SOTA EfficientNet-V2-L (Custom Head)...")
    
    # 1. åˆå§‹åŒ–éª¨å¹²ç½‘
    net = models.efficientnet_v2_l(weights=None)
    
    # 2. è·å–åŸå§‹è¾“å…¥ç»´åº¦ (é€šå¸¸æ˜¯ 1280)
    num_ftrs = net.classifier[-1].in_features
    
    # 3. [å…³é”®] é‡å»ºä¸è®­ç»ƒä»£ç å®Œå…¨ä¸€è‡´çš„åˆ†ç±»å¤´
    # è®­ç»ƒä»£ç åŸæ–‡:
    # model.classifier = nn.Sequential(
    #     nn.Dropout(p=0.4),
    #     nn.Linear(num_ftrs, 1024),
    #     nn.SiLU(),
    #     nn.Dropout(p=0.3),
    #     nn.Linear(1024, 2)
    # )
    net.classifier = nn.Sequential(
        nn.Dropout(p=0.4),
        nn.Linear(num_ftrs, 1024),
        nn.SiLU(),
        nn.Dropout(p=0.3),
        nn.Linear(1024, 2)
    )
    
    # 4. åŠ è½½æƒé‡
    net.load_state_dict(state_dict)
    return net

def get_model():
    global model, model_name
    if model is not None:
        return model
    
    print(f"â³ [ç³»ç»Ÿ] å¼€å§‹åŠ è½½æ¨¡å‹æ–‡ä»¶: {MODEL_PATH}")
    
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {MODEL_PATH}")

    try:
        # è¯»å–æƒé‡
        state_dict = torch.load(MODEL_PATH, map_location=DEVICE)
        
        # æ„å»ºæ¨¡å‹
        model = try_load_sota_model(state_dict)
        model_name = "SOTA-EffNetV2-L"
        print("âœ… æˆåŠŸåŒ¹é…æ¶æ„: SOTA EfficientNet-V2-L")

        model.eval()
        return model
        
    except Exception as e:
        print(f"âŒ è‡´å‘½é”™è¯¯: {traceback.format_exc()}")
        raise e

# ==========================================
# è·¯ç”±
# ==========================================

@app.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'ok', 'loaded_model': model_name})

@app.route('/api/predict', methods=['POST'])
def predict():
    global model
    
    try:
        if model is None:
            model = get_model()
            
        if 'file' not in request.files:
            return jsonify({'error': 'No file part'}), 400
        file = request.files['file']
        
        # è¯»å–å›¾ç‰‡
        img_bytes = file.read()
        image = Image.open(io.BytesIO(img_bytes)).convert('RGB')
        
        # [å…³é”®] é¢„å¤„ç†å¿…é¡»ä¸è®­ç»ƒä»£ç ä¸€è‡´
        # è®­ç»ƒä»£ç : val_transform = A.Compose([A.Resize(224), A.Normalize(mean=[0.485...], std=[0.229...])])
        transform = transforms.Compose([
            transforms.Resize((224, 224)), # è®­ç»ƒä»£ç  INPUT_SIZE = 224
            transforms.ToTensor(),
            # ä½¿ç”¨ ImageNet æ ‡å‡†å‡å€¼æ–¹å·® (è®­ç»ƒä»£ç ç”¨çš„æ˜¯è¿™ä¸ªï¼Œä¸æ˜¯ 0.5)
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406], 
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        tensor = transform(image).unsqueeze(0)
        
        # æ¨ç†
        with torch.no_grad():
            outputs = model(tensor)
            probs = torch.nn.functional.softmax(outputs, dim=1)
            
            # è®­ç»ƒä»£ç ä¸­: Label 0=Real, 1=Fake (é€šè¿‡ RobustDataset é€»è¾‘æ¨æ–­)
            # å‡å®š fake_keys å¯¹åº” label 1
            fake_prob = probs[0][1].item()
            is_fake = fake_prob > 0.5
            confidence = fake_prob if is_fake else (1 - fake_prob)
            
            return jsonify({
                'label': 'AIGC Fake' if is_fake else 'Real Photo',
                'is_fake': is_fake,
                'confidence': float(confidence),
                'score': float(fake_prob),
                'model_used': model_name
            })
            
    except Exception as e:
        error_msg = traceback.format_exc()
        print(f"è¯·æ±‚å¤„ç†å¤±è´¥: {error_msg}")
        return jsonify({'error': 'åç«¯æŠ¥é”™', 'details': str(e), 'trace': error_msg}), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)